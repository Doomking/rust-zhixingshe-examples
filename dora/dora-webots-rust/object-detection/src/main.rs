use anyhow::Context;
use dora_node_api::{
    arrow::array::UInt8Array, dora_core::config::DataId, DoraNode, Event, Parameter,
};
use opencv::{
    core::{copy_make_border, AlgorithmHint, Rect, Scalar, Vec4b},
    imgproc,
    prelude::*,
};
use std::error::Error;

use candle_core::{DType, Device, Module, Tensor};
use candle_nn::VarBuilder;
// use hf_hub::api::sync::Api;

use std::env;
use std::path::Path;

mod model;

use model::{Multiples, YoloV8};

mod utils;

use utils::bboxes_to_arrow;

// --- å¸¸é‡å®šä¹‰ ---
const CONFIDENCE_THRESHOLD: f32 = 0.25;
const IOU_THRESHOLD: f32 = 0.45;
const MODEL_SIZE: usize = 640; // YOLOv8 æ ‡å‡†è¾“å…¥å¤§å°
const LABELS: [&str; 80] = [
    "person",
    "bicycle",
    "car",
    "motorcycle",
    "airplane",
    "bus",
    "train",
    "truck",
    "boat",
    "traffic light",
    "fire hydrant",
    "stop sign",
    "parking meter",
    "bench",
    "bird",
    "cat",
    "dog",
    "horse",
    "sheep",
    "cow",
    "elephant",
    "bear",
    "zebra",
    "giraffe",
    "backpack",
    "umbrella",
    "handbag",
    "tie",
    "suitcase",
    "frisbee",
    "skis",
    "snowboard",
    "sports ball",
    "kite",
    "baseball bat",
    "baseball glove",
    "skateboard",
    "surfboard",
    "tennis racket",
    "bottle",
    "wine glass",
    "cup",
    "fork",
    "knife",
    "spoon",
    "bowl",
    "banana",
    "apple",
    "sandwich",
    "orange",
    "broccoli",
    "carrot",
    "hot dog",
    "pizza",
    "donut",
    "cake",
    "chair",
    "couch",
    "potted plant",
    "bed",
    "dining table",
    "toilet",
    "tv",
    "laptop",
    "mouse",
    "remote",
    "keyboard",
    "cell phone",
    "microwave",
    "oven",
    "toaster",
    "sink",
    "refrigerator",
    "book",
    "clock",
    "vase",
    "scissors",
    "teddy bear",
    "hair drier",
    "toothbrush",
];

pub fn select_device() -> Result<Device, Box<dyn Error>> {
    // å°è¯• Metal è®¾å¤‡ (å¦‚æœ 'metal' ç‰¹æ€§å·²å¯ç”¨)
    if let Ok(device) = Device::new_metal(0) {
        println!("ğŸš€ Using Metal device.");
        return Ok(device);
    }

    // å›é€€åˆ° CPU
    println!("ğŸ¢ Using CPU device.");
    Ok(Device::Cpu)
}

fn main() -> Result<(), Box<dyn Error>> {
    let (mut node, mut events) = DoraNode::init_from_env()?;
    let output = DataId::from("detections".to_owned());
    // åŠ è½½ YOLOv8 æ¨¡å‹ (ä½¿ç”¨ HuggingFace è‡ªåŠ¨ä¸‹è½½)
    println!("Loading YOLOv8 model...");
    // ä¼˜åŒ–å (å¦‚æœæ”¯æŒ CUDA):
    let device = select_device().unwrap();
    // let api = Api::new()?;
    // let repo = api.model("/lmz/candle-yolo-v8".to_string());
    // let model_file = repo.get("yolov8n.safetensors")?;

    // https://hf-mirror.com/lmz/candle-yolo-v8/tree/main
    // å®šä¹‰æœ¬åœ°æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„
    let current_dir = env::current_dir().context("Failed to get current working directory")?;

    // å®šä¹‰ç›¸å¯¹è·¯å¾„
    let relative_path = Path::new("object-detection/models/yolov8n.safetensors");

    //  å°è¯•åˆå¹¶è·¯å¾„å¹¶æ£€æŸ¥
    let local_model_path = current_dir.join(relative_path);
    // éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
    if !local_model_path.exists() {
        return Err(format!("Model file not found at: {}", local_model_path.display()).into());
    }
    let model_file = local_model_path;
    // åŠ è½½æƒé‡
    let vb = unsafe { VarBuilder::from_mmaped_safetensors(&[model_file], DType::F32, &device)? };
    let model = YoloV8::load(vb, Multiples::n(), 80)?;

    println!("Model loaded successfully.");

    while let Some(event) = events.recv() {
        // println!("Received event: {:?}", event);
        match event {
            Event::Input { id, metadata, data } => match id.as_str() {
                "frame" => {
                    // å°è¯•è·å– width
                    let cols = match metadata.parameters.get("width") {
                        Some(Parameter::Integer(v)) => *v as i32,
                        _ => 640, // é»˜è®¤å€¼
                    };

                    // å°è¯•è·å– height
                    let rows = match metadata.parameters.get("height") {
                        Some(Parameter::Integer(v)) => *v as i32,
                        _ => 480, // é»˜è®¤å€¼
                    };
                    // å°†æ¥æ”¶åˆ°çš„å­—èŠ‚æ•°æ®è½¬æ¢ä¸º OpenCV Vector
                    // 1. å°† Arrow trait å¯¹è±¡å¼ºè½¬ä¸ºå…·ä½“çš„ UInt8Array
                    let uint8_array = data
                        .as_any()
                        .downcast_ref::<UInt8Array>()
                        .context("Arrow data is not UInt8Array (expected byte array)")?;

                    // 2. æå– UInt8Array çš„å­—èŠ‚åˆ‡ç‰‡
                    let byte_slice = uint8_array.values(); // è¿”å› &[u8]
                    if byte_slice.len() != (rows * cols * 4) as usize {
                        eprintln!(
                            "Data size mismatch! Expected {}, got {}",
                            rows * cols * 4,
                            byte_slice.len()
                        );
                        continue;
                    }

                    // å…³é”®ç‚¹ï¼šå°† &[u8] è½¬æ¢ä¸º &[Vec4b]
                    // Vec4b ä»£è¡¨ä¸€ä¸ªç”± 4 ä¸ª u8 ç»„æˆçš„åƒç´ ç‚¹
                    let (head, vec4_slice, tail) = unsafe { byte_slice.align_to::<Vec4b>() };

                    if !head.is_empty() || !tail.is_empty() {
                        // å¦‚æœæ•°æ®ä¸æ˜¯ 4 çš„å€æ•°ï¼Œå¯èƒ½ä¼šè¿›åˆ°è¿™é‡Œ
                        eprintln!("Warning: Byte slice alignment issue");
                    }

                    // ç°åœ¨ä¼ å…¥åªæœ‰ 3 ä¸ªå‚æ•°çš„å‡½æ•°
                    // å› ä¸º vec4_slice çš„é•¿åº¦åˆšå¥½æ˜¯ byte_slice.len() / 4
                    // 128 * 64 = 8192ï¼Œè¿™ä¸ vec4_slice.len() å®Œç¾åŒ¹é…ï¼
                    let frame_raw = Mat::new_rows_cols_with_data(
                        rows,       // 128 (è¡Œ)
                        cols,       // 64 (åˆ—)
                        vec4_slice, // 32768å­—èŠ‚çš„ u8 åˆ‡ç‰‡ç°åœ¨å˜æˆäº† 8192é•¿åº¦çš„ Vec4b åˆ‡ç‰‡
                    )?;

                    // let frame_raw = Mat::new_rows_cols_with_data(
                    //     rows,       // ç¬¬1ä¸ªå‚æ•°: i32
                    //     cols,       // ç¬¬2ä¸ªå‚æ•°: i32
                    //     byte_slice, // åªéœ€è¦ä¼ å…¥åˆ‡ç‰‡æœ¬èº«ï¼Œä¸è¦ä¼ æŒ‡é’ˆå’Œé•¿åº¦
                    // )?;
                    let mut frame = Mat::default();
                    // æ³¨æ„ï¼šWebots çš„é¢œè‰²é¡ºåºå¯èƒ½æ˜¯ BGRAï¼Œå¦‚æœé¢œè‰²ä¸å¯¹ï¼Œè¯·å°è¯• COLOR_BGRA2RGB
                    imgproc::cvt_color(
                        &frame_raw,
                        &mut frame,
                        imgproc::COLOR_BGRA2BGR,
                        0,
                        AlgorithmHint::ALGO_HINT_DEFAULT,
                    )?;

                    if frame.empty() {
                        eprintln!("Warning: Decoded frame is empty. Skipping this iteration.");
                        continue; // è·³è¿‡å½“å‰å¾ªç¯ï¼Œä¸è¿›å…¥ preprocess_image
                    }
                    // --- æ­¥éª¤ A: å›¾åƒé¢„å¤„ç† (OpenCV -> Candle Tensor) ---
                    let (processed_tensor, ratio, pad_w, pad_h) =
                        preprocess_image(&frame, &device)?;

                    // --- æ­¥éª¤ B: æ¨¡å‹æ¨ç† ---
                    let predictions = model.forward(&processed_tensor)?;

                    // --- æ­¥éª¤ C: åå¤„ç† (NMS) ---
                    // predictions ç»´åº¦é€šå¸¸æ˜¯ (1, 84, 8400) -> (Batch, Classes+Coords, Anchors)
                    let preds = predictions.squeeze(0)?;
                    let (bboxes, keypoints) = report_detect(&preds, &frame, ratio, pad_w, pad_h)?;

                    let arrow_array = bboxes_to_arrow(bboxes)?;

                    node.send_output(output.clone(), metadata.parameters, arrow_array)?;
                }
                other => eprintln!("Received input `{other}`"),
            },
            _ => {}
        }
    }

    Ok(())
}

// å›¾åƒé¢„å¤„ç†ï¼šè°ƒæ•´å¤§å°ã€å¡«å……ã€å½’ä¸€åŒ–ã€è½¬ Tensor
fn preprocess_image(
    frame: &Mat,
    device: &Device,
) -> Result<(Tensor, f32, f32, f32), Box<dyn Error>> {
    let width = frame.cols();
    let height = frame.rows();

    // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒé•¿å®½æ¯”
    let ratio = (MODEL_SIZE as f32 / width.max(height) as f32).min(1.0);
    let new_w = (width as f32 * ratio) as i32;
    let new_h = (height as f32 * ratio) as i32;

    // Resize
    let mut resized = Mat::default();
    imgproc::resize(
        frame,
        &mut resized,
        opencv::core::Size::new(new_w, new_h),
        0.0,
        0.0,
        imgproc::INTER_LINEAR,
    )?;

    // Letterbox padding (å¡«å……ç°è‰²èƒŒæ™¯åˆ° 640x640)
    let dw = (MODEL_SIZE as i32 - new_w) / 2;
    let dh = (MODEL_SIZE as i32 - new_h) / 2;

    let mut padded = Mat::default();
    copy_make_border(
        &resized,
        &mut padded,
        dh,
        MODEL_SIZE as i32 - new_h - dh, // top, bottom
        dw,
        MODEL_SIZE as i32 - new_w - dw, // left, right
        opencv::core::BORDER_CONSTANT,
        Scalar::new(114.0, 114.0, 114.0, 0.0), // YOLO ç°è‰²èƒŒæ™¯
    )?;

    // BGR -> RGB
    let mut rgb = Mat::default();
    imgproc::cvt_color(
        &padded,
        &mut rgb,
        imgproc::COLOR_BGR2RGB,
        0,
        AlgorithmHint::ALGO_HINT_DEFAULT,
    )?;

    // è½¬ä¸º Vec<u8>
    let data_vec: Vec<u8> = rgb.data_bytes()?.to_vec();

    // è½¬ä¸º Candle Tensor: (Batch, Channel, Height, Width)
    // åŸå§‹æ•°æ®æ˜¯ HWC (640, 640, 3)ï¼Œéœ€è¦è½¬ä¸º CHW å¹¶å½’ä¸€åŒ– 0-1
    let tensor = Tensor::from_vec(data_vec, (MODEL_SIZE, MODEL_SIZE, 3), device)?
        .permute((2, 0, 1))? // HWC -> CHW
        .to_dtype(DType::F32)?
        .affine(1. / 255., 0.)? // å½’ä¸€åŒ–
        .unsqueeze(0)?; // æ·»åŠ  Batch ç»´åº¦ -> (1, 3, 640, 640)

    Ok((tensor, ratio, dw as f32, dh as f32))
}

/// è§£ææ¨ç†ç»“æœ
/// YOLOv8 Output: [batch, 84, 8400] (xc, yc, w, h, class0...class79)
fn report_detect(
    pred: &Tensor,
    original_frame: &Mat,
    ratio: f32,
    pad_w: f32,
    pad_h: f32,
) -> Result<(Vec<(&'static str, Rect, f32)>, Option<Vec<()>>), Box<dyn Error>> {
    // 1. è½¬ç½®ä¸º [8400, 84] ä¾¿äºå¤„ç†
    let pred = pred.t()?;
    let (n_preds, _n_coords) = pred.dims2()?;
    let pred_vec: Vec<Vec<f32>> = pred.to_vec2()?; // è·å–æ•°æ®åˆ° CPU

    let mut results = Vec::new();

    for i in 0..n_preds {
        let row = &pred_vec[i];

        // æ‰¾å‡ºæœ€é«˜åˆ†çš„ç±»åˆ« (å‰4ä¸ªæ˜¯åæ ‡ï¼Œåé¢æ˜¯ç±»åˆ«)
        let scores = &row[4..];
        let (max_score_idx, max_score) =
            scores
                .iter()
                .enumerate()
                .fold(
                    (0, 0.0_f32),
                    |(idx, max), (i, &val)| {
                        if val > max {
                            (i, val)
                        } else {
                            (idx, max)
                        }
                    },
                );

        if max_score > CONFIDENCE_THRESHOLD {
            // è§£æåæ ‡ (cx, cy, w, h) -> æ¨¡å‹è¾“å…¥åæ ‡ç³»
            let cx = row[0];
            let cy = row[1];
            let w = row[2];
            let h = row[3];

            // è½¬æ¢å›åŸå›¾åæ ‡ (å»é™¤ padding å¹¶é™¤ä»¥ç¼©æ”¾æ¯”ä¾‹)
            let x = ((cx - w / 2.0 - pad_w) / ratio).max(0.0);
            let y = ((cy - h / 2.0 - pad_h) / ratio).max(0.0);
            let width = (w / ratio).min(original_frame.cols() as f32 - x);
            let height = (h / ratio).min(original_frame.rows() as f32 - y);

            results.push((
                LABELS[max_score_idx],
                Rect::new(x as i32, y as i32, width as i32, height as i32),
                max_score,
            ));
        }
    }

    // ç®€å• NMS (éæå¤§å€¼æŠ‘åˆ¶)
    // æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ torchvision æˆ– opencv è‡ªå¸¦çš„ NMSBoxes
    let mut kept_results = Vec::new();
    results.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap()); // æŒ‰ç½®ä¿¡åº¦é™åº

    while let Some(current) = results.pop() {
        kept_results.push(current.clone());
        // ç§»é™¤ IOU å¤§äºé˜ˆå€¼çš„æ¡†
        results.retain(|item| iou(&current.1, &item.1) < IOU_THRESHOLD);
    }

    Ok((kept_results, None))
}

// è®¡ç®—ä¸¤ä¸ª Rect çš„ IOU
fn iou(box_a: &Rect, box_b: &Rect) -> f32 {
    let x_a = box_a.x.max(box_b.x);
    let y_a = box_a.y.max(box_b.y);
    let x_b = (box_a.x + box_a.width).min(box_b.x + box_b.width);
    let y_b = (box_a.y + box_a.height).min(box_b.y + box_b.height);

    let inter_area = (x_b - x_a).max(0) as f32 * (y_b - y_a).max(0) as f32;
    let box_a_area = (box_a.width * box_a.height) as f32;
    let box_b_area = (box_b.width * box_b.height) as f32;

    inter_area / (box_a_area + box_b_area - inter_area)
}
